{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # load and manipulate data\n",
    "import numpy as np # calculation\n",
    "import matplotlib.pyplot as plt # visualize data\n",
    "from sklearn.preprocessing import OneHotEncoder # To one-hot encode variables\n",
    "import category_encoders as ce # To target encode high cardinality variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load raw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand = pd.read_csv('shopee_raw_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       date  product_id                                                                                    product_name     product_category    brand  traffic  impressions  payment  revenue  product_ad_spend  shop_ad_spend  auto_ad_spend  run_shop_ad  run_product_ad  product_page_bounce_count  traffic_from_search  wm_yr_wk  month  d  doubleday  near_dday  end_of_month  weekend  other_commercial_sale  day_offs  avg_price  promotion_on  promotion_price price_bin discount_rate  comment_received  product_rating  high_rating  high_discount  high_comment  avg_category_rate  avg_category_comment  week_of_month  wday  day_of_year\n",
      "0  5/1/2024  3388329772  Combo 12 h?p cà phê viên nén Carraro  - Nh?p kh?u t? Ý - Tuong thích v?i máy capsule Nespresso  3. Carraro capsules  Carraro        0            0        0        0                 0             67          30000            1               1                          0                    0    202417      5  1          0          0             0        0                      0         1    1166400             0          1166400     cheap            0%                45             4.8            1              0             1                4.9                    31              1     3          122\n",
      "1  5/2/2024  3388329772  Combo 12 h?p cà phê viên nén Carraro  - Nh?p kh?u t? Ý - Tuong thích v?i máy capsule Nespresso  3. Carraro capsules  Carraro        0            0        0        0                 0           5089          30000            1               1                          0                    0    202417      5  2          0          0             0        0                      0         0    1166400             0          1166400     cheap            0%                45             4.8            1              0             1                4.9                    31              1     4          123\n",
      "2  5/3/2024  3388329772  Combo 12 h?p cà phê viên nén Carraro  - Nh?p kh?u t? Ý - Tuong thích v?i máy capsule Nespresso  3. Carraro capsules  Carraro        0            0        0        0                 0           8849          30000            1               1                          0                    0    202417      5  3          0          0             0        0                      0         0    1166400             0          1166400     cheap            0%                45             4.8            1              0             1                4.9                    31              1     5          124\n",
      "3  5/4/2024  3388329772  Combo 12 h?p cà phê viên nén Carraro  - Nh?p kh?u t? Ý - Tuong thích v?i máy capsule Nespresso  3. Carraro capsules  Carraro        0            0        0        0                 0          11675          30000            1               1                          0                    0    202417      5  4          0          1             0        1                      0         0    1166400             0          1166400     cheap            0%                45             4.8            1              0             1                4.9                    31              1     6          125\n",
      "4  5/5/2024  3388329772  Combo 12 h?p cà phê viên nén Carraro  - Nh?p kh?u t? Ý - Tuong thích v?i máy capsule Nespresso  3. Carraro capsules  Carraro        0            0        0        0                 0          19085          25000            1               1                          0                    0    202418      5  5          1          0             0        1                      0         0    1166400             0          1166400     cheap            0%                45             4.8            1              0             1                4.9                    31              1     7          126\n"
     ]
    }
   ],
   "source": [
    "print(demand.head().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column Name</th>\n",
       "      <th>Unique Value Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>date</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>product_id</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>product_name</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>product_category</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>brand</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>traffic</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>impressions</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>payment</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>revenue</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>product_ad_spend</td>\n",
       "      <td>567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>shop_ad_spend</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>auto_ad_spend</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>run_shop_ad</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>run_product_ad</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>product_page_bounce_count</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>traffic_from_search</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>wm_yr_wk</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>month</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>d</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>doubleday</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>near_dday</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>end_of_month</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>weekend</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>other_commercial_sale</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>day_offs</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>avg_price</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>promotion_on</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>promotion_price</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>price_bin</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>discount_rate</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>comment_received</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>product_rating</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>high_rating</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>high_discount</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>high_comment</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>avg_category_rate</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>avg_category_comment</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>week_of_month</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>wday</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>day_of_year</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Column Name  Unique Value Count\n",
       "0                        date                 214\n",
       "1                  product_id                 131\n",
       "2                product_name                 133\n",
       "3            product_category                  20\n",
       "4                       brand                  13\n",
       "5                     traffic                  56\n",
       "6                 impressions                  97\n",
       "7                     payment                  12\n",
       "8                     revenue                1185\n",
       "9            product_ad_spend                 567\n",
       "10              shop_ad_spend                 161\n",
       "11              auto_ad_spend                   9\n",
       "12                run_shop_ad                   2\n",
       "13             run_product_ad                   2\n",
       "14  product_page_bounce_count                  20\n",
       "15        traffic_from_search                  36\n",
       "16                   wm_yr_wk                  31\n",
       "17                      month                   7\n",
       "18                          d                 214\n",
       "19                  doubleday                   2\n",
       "20                  near_dday                   2\n",
       "21               end_of_month                   2\n",
       "22                    weekend                   2\n",
       "23      other_commercial_sale                   2\n",
       "24                   day_offs                   2\n",
       "25                  avg_price                  84\n",
       "26               promotion_on                   2\n",
       "27            promotion_price                  97\n",
       "28                  price_bin                   4\n",
       "29              discount_rate                  12\n",
       "30           comment_received                  33\n",
       "31             product_rating                   7\n",
       "32                high_rating                   2\n",
       "33              high_discount                   2\n",
       "34               high_comment                   2\n",
       "35          avg_category_rate                   4\n",
       "36       avg_category_comment                  12\n",
       "37              week_of_month                   6\n",
       "38                       wday                   7\n",
       "39                day_of_year                 214"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_unique_values(df):\n",
    "    unique_values = {col: df[col].nunique() for col in df.columns}\n",
    "    result_df = pd.DataFrame(list(unique_values.items()), columns=[\"Column Name\", \"Unique Value Count\"])\n",
    "    return result_df\n",
    "\n",
    "check_unique_values(demand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28676 entries, 0 to 28675\n",
      "Data columns (total 40 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   date                       28676 non-null  object \n",
      " 1   product_id                 28676 non-null  int64  \n",
      " 2   product_name               28676 non-null  object \n",
      " 3   product_category           28676 non-null  object \n",
      " 4   brand                      28676 non-null  object \n",
      " 5   traffic                    28676 non-null  int64  \n",
      " 6   impressions                28676 non-null  int64  \n",
      " 7   payment                    28676 non-null  int64  \n",
      " 8   revenue                    28676 non-null  int64  \n",
      " 9   product_ad_spend           28676 non-null  int64  \n",
      " 10  shop_ad_spend              28676 non-null  int64  \n",
      " 11  auto_ad_spend              28676 non-null  int64  \n",
      " 12  run_shop_ad                28676 non-null  int64  \n",
      " 13  run_product_ad             28676 non-null  int64  \n",
      " 14  product_page_bounce_count  28676 non-null  int64  \n",
      " 15  traffic_from_search        28676 non-null  int64  \n",
      " 16  wm_yr_wk                   28676 non-null  int64  \n",
      " 17  month                      28676 non-null  int64  \n",
      " 18  d                          28676 non-null  int64  \n",
      " 19  doubleday                  28676 non-null  int64  \n",
      " 20  near_dday                  28676 non-null  int64  \n",
      " 21  end_of_month               28676 non-null  int64  \n",
      " 22  weekend                    28676 non-null  int64  \n",
      " 23  other_commercial_sale      28676 non-null  int64  \n",
      " 24  day_offs                   28676 non-null  int64  \n",
      " 25  avg_price                  28676 non-null  int64  \n",
      " 26  promotion_on               28676 non-null  int64  \n",
      " 27  promotion_price            28676 non-null  int64  \n",
      " 28  price_bin                  28676 non-null  object \n",
      " 29  discount_rate              28676 non-null  object \n",
      " 30  comment_received           28676 non-null  int64  \n",
      " 31  product_rating             28676 non-null  float64\n",
      " 32  high_rating                28676 non-null  int64  \n",
      " 33  high_discount              28676 non-null  int64  \n",
      " 34  high_comment               28676 non-null  int64  \n",
      " 35  avg_category_rate          28676 non-null  float64\n",
      " 36  avg_category_comment       28676 non-null  int64  \n",
      " 37  week_of_month              28676 non-null  int64  \n",
      " 38  wday                       28676 non-null  int64  \n",
      " 39  day_of_year                28676 non-null  int64  \n",
      "dtypes: float64(2), int64(32), object(6)\n",
      "memory usage: 8.8+ MB\n"
     ]
    }
   ],
   "source": [
    "demand.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like we have some issues:\n",
    "* Misalignment between `product_id` and `product_name`\n",
    "* Some variables in the wrong data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`date` should be in datetime data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the 'date' column is in datetime format\n",
    "demand['date'] = pd.to_datetime(demand['date'])\n",
    "\n",
    "# Sort the data by date, then product_id\n",
    "demand = demand.sort_values(by=['product_id', 'date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`discount_rate` should be float   \n",
    "\n",
    "`product_id` should be string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'discount_rate' to float\n",
    "demand['discount_rate'] = pd.to_numeric(\n",
    "    demand['discount_rate'].str.replace('%', '', regex=False), \n",
    "    errors='coerce'\n",
    ").astype(float).round(4)\n",
    "\n",
    "# Convert 'product_id' to string\n",
    "demand['product_id'] = demand['product_id'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28676 entries, 0 to 28675\n",
      "Data columns (total 40 columns):\n",
      " #   Column                     Non-Null Count  Dtype         \n",
      "---  ------                     --------------  -----         \n",
      " 0   date                       28676 non-null  datetime64[ns]\n",
      " 1   product_id                 28676 non-null  object        \n",
      " 2   product_name               28676 non-null  object        \n",
      " 3   product_category           28676 non-null  object        \n",
      " 4   brand                      28676 non-null  object        \n",
      " 5   traffic                    28676 non-null  int64         \n",
      " 6   impressions                28676 non-null  int64         \n",
      " 7   payment                    28676 non-null  int64         \n",
      " 8   revenue                    28676 non-null  int64         \n",
      " 9   product_ad_spend           28676 non-null  int64         \n",
      " 10  shop_ad_spend              28676 non-null  int64         \n",
      " 11  auto_ad_spend              28676 non-null  int64         \n",
      " 12  run_shop_ad                28676 non-null  int64         \n",
      " 13  run_product_ad             28676 non-null  int64         \n",
      " 14  product_page_bounce_count  28676 non-null  int64         \n",
      " 15  traffic_from_search        28676 non-null  int64         \n",
      " 16  wm_yr_wk                   28676 non-null  int64         \n",
      " 17  month                      28676 non-null  int64         \n",
      " 18  d                          28676 non-null  int64         \n",
      " 19  doubleday                  28676 non-null  int64         \n",
      " 20  near_dday                  28676 non-null  int64         \n",
      " 21  end_of_month               28676 non-null  int64         \n",
      " 22  weekend                    28676 non-null  int64         \n",
      " 23  other_commercial_sale      28676 non-null  int64         \n",
      " 24  day_offs                   28676 non-null  int64         \n",
      " 25  avg_price                  28676 non-null  int64         \n",
      " 26  promotion_on               28676 non-null  int64         \n",
      " 27  promotion_price            28676 non-null  int64         \n",
      " 28  price_bin                  28676 non-null  object        \n",
      " 29  discount_rate              28676 non-null  float64       \n",
      " 30  comment_received           28676 non-null  int64         \n",
      " 31  product_rating             28676 non-null  float64       \n",
      " 32  high_rating                28676 non-null  int64         \n",
      " 33  high_discount              28676 non-null  int64         \n",
      " 34  high_comment               28676 non-null  int64         \n",
      " 35  avg_category_rate          28676 non-null  float64       \n",
      " 36  avg_category_comment       28676 non-null  int64         \n",
      " 37  week_of_month              28676 non-null  int64         \n",
      " 38  wday                       28676 non-null  int64         \n",
      " 39  day_of_year                28676 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(3), int64(31), object(5)\n",
      "memory usage: 8.8+ MB\n"
     ]
    }
   ],
   "source": [
    "demand.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date  product_id                                                                                    product_name     product_category    brand  traffic  impressions  payment  revenue  product_ad_spend  shop_ad_spend  auto_ad_spend  run_shop_ad  run_product_ad  product_page_bounce_count  traffic_from_search  wm_yr_wk  month  d  doubleday  near_dday  end_of_month  weekend  other_commercial_sale  day_offs  avg_price  promotion_on  promotion_price price_bin  discount_rate  comment_received  product_rating  high_rating  high_discount  high_comment  avg_category_rate  avg_category_comment  week_of_month  wday  day_of_year\n",
      "0 2024-05-01  3388329772  Combo 12 h?p cà phê viên nén Carraro  - Nh?p kh?u t? Ý - Tuong thích v?i máy capsule Nespresso  3. Carraro capsules  Carraro        0            0        0        0                 0             67          30000            1               1                          0                    0    202417      5  1          0          0             0        0                      0         1    1166400             0          1166400     cheap            0.0                45             4.8            1              0             1                4.9                    31              1     3          122\n",
      "1 2024-05-02  3388329772  Combo 12 h?p cà phê viên nén Carraro  - Nh?p kh?u t? Ý - Tuong thích v?i máy capsule Nespresso  3. Carraro capsules  Carraro        0            0        0        0                 0           5089          30000            1               1                          0                    0    202417      5  2          0          0             0        0                      0         0    1166400             0          1166400     cheap            0.0                45             4.8            1              0             1                4.9                    31              1     4          123\n",
      "2 2024-05-03  3388329772  Combo 12 h?p cà phê viên nén Carraro  - Nh?p kh?u t? Ý - Tuong thích v?i máy capsule Nespresso  3. Carraro capsules  Carraro        0            0        0        0                 0           8849          30000            1               1                          0                    0    202417      5  3          0          0             0        0                      0         0    1166400             0          1166400     cheap            0.0                45             4.8            1              0             1                4.9                    31              1     5          124\n",
      "3 2024-05-04  3388329772  Combo 12 h?p cà phê viên nén Carraro  - Nh?p kh?u t? Ý - Tuong thích v?i máy capsule Nespresso  3. Carraro capsules  Carraro        0            0        0        0                 0          11675          30000            1               1                          0                    0    202417      5  4          0          1             0        1                      0         0    1166400             0          1166400     cheap            0.0                45             4.8            1              0             1                4.9                    31              1     6          125\n",
      "4 2024-05-05  3388329772  Combo 12 h?p cà phê viên nén Carraro  - Nh?p kh?u t? Ý - Tuong thích v?i máy capsule Nespresso  3. Carraro capsules  Carraro        0            0        0        0                 0          19085          25000            1               1                          0                    0    202418      5  5          1          0             0        1                      0         0    1166400             0          1166400     cheap            0.0                45             4.8            1              0             1                4.9                    31              1     7          126\n"
     ]
    }
   ],
   "source": [
    "print(demand.head().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix misalignment between `product_id` and `product_name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     product_id  product_name\n",
      "43  15765129329             2\n",
      "76  21382736254             2\n",
      "81  22150796991             2\n",
      "Check these product_ids for misalignment between product_id and product_name:\n",
      "['15765129329', '21382736254', '22150796991']\n"
     ]
    }
   ],
   "source": [
    "def check_row_misalignment(df, col1, col2):\n",
    "    misaligned = df.groupby(col1)[col2].nunique().reset_index()\n",
    "    misaligned = misaligned[misaligned[col2] > 1]\n",
    "    return misaligned\n",
    "\n",
    "misaligned_rows = check_row_misalignment(demand, 'product_id', 'product_name')\n",
    "print(misaligned_rows)\n",
    "\n",
    "misaligned_product_ids = misaligned_rows['product_id'].tolist()\n",
    "\n",
    "print(\"Check these product_ids for misalignment between product_id and product_name:\")\n",
    "print(misaligned_product_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # I check it manually with excel to investigate, if you want to see for yourself, you can uncomment these lines\n",
    "\n",
    "# filtered_by_product_id = demand[demand['product_id'].isin(misaligned_product_ids)]\n",
    "\n",
    "# # Check the shape of the DataFrame\n",
    "# rows, columns = filtered_by_product_id.shape\n",
    "\n",
    "# print(f\"Number of rows: {rows}\")\n",
    "# print(f\"Number of columns: {columns}\")\n",
    "\n",
    "# # Export data to check in excel\n",
    "# filtered_by_product_id.to_csv('filtered_by_product_id.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I examined the data and see that there are dates where `product_name` A in `product_id` 1 had data. Within that same date, `product_name` B corresponding to the same `product_id` has 0 for its variables. And vice versa. So I'll keep rows where the `product_id` has \"meaningful data\" (non-zero values for its important variables), and eliminate rows where the `product_id` carries 0 for its variables (impressions, traffic, etc.) in another `product_name` for the same `date`.\n",
    "\n",
    "This is because in November, the sales admin changed the content of the product pages: keeping high performing `product_id` (meaning the `product_id` contains high rating, high comment volumes, etc), merging low performing products into that `product_id` and then changed the name of the corresponding `product_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4840/3250136266.py:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  filtered_demand = filtered_demand.groupby(['date', 'product_id'], group_keys=False).apply(filter_impressions_and_payment)\n"
     ]
    }
   ],
   "source": [
    "# Filter the DataFrame for misaligned product_ids\n",
    "filtered_demand = demand[demand['product_id'].isin(misaligned_product_ids)]\n",
    "\n",
    "# Case 1: Remove duplicate rows based on the specified subset of columns\n",
    "filtered_demand = filtered_demand.drop_duplicates(subset=['date', 'product_id', 'traffic', 'impressions', 'payment'])\n",
    "\n",
    "# Case 2: After Case 1, check for each combination of date & product_id, if there are 2 rows,\n",
    "# keep the row with impressions > 0 or payment > 0, else remove the row with impressions = 0.\n",
    "def filter_impressions_and_payment(group):\n",
    "    if len(group) == 2:  # Ensure there are exactly 2 rows per combination\n",
    "        # Check for rows where impressions = 0 and the other row has either impressions > 0 or payment > 0\n",
    "        if (group['impressions'] == 0).any() and ((group['impressions'] > 0).any() or (group['payment'] > 0).any()):\n",
    "            # Keep the row where impressions > 0 or payment > 0\n",
    "            group = group[(group['impressions'] > 0) | (group['payment'] > 0)]\n",
    "    return group\n",
    "\n",
    "# Apply the filtering logic only to the filtered DataFrame\n",
    "filtered_demand = filtered_demand.groupby(['date', 'product_id'], group_keys=False).apply(filter_impressions_and_payment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows (all dates) for each product_id:\n",
      "product_id\n",
      "15765129329    214\n",
      "21382736254    214\n",
      "22150796991    214\n",
      "Name: date, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Group by 'product_id' and count the number of rows for each\n",
    "date_counts = filtered_demand.groupby('product_id')['date'].count()\n",
    "\n",
    "# Set display option to show all rows\n",
    "pd.set_option('display.max_rows', None)\n",
    "# pd.reset_option('display.max_rows')\n",
    "\n",
    "# Print the total counts for each product_id\n",
    "print(\"Total rows (all dates) for each product_id:\")\n",
    "print(date_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's aligned now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the original DataFrame with the modified rows for misaligned product_ids\n",
    "# First, drop the rows for the misaligned product_ids from the original DataFrame\n",
    "demand = demand[~demand['product_id'].isin(misaligned_product_ids)]\n",
    "\n",
    "# Then, append the filtered DataFrame back\n",
    "demand = pd.concat([demand, filtered_demand], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensure order of `date` for each `product_id`\n",
    "Sorting will be applied first by `product_id` and then by `date`for creating lagging, and rolling features later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_category</th>\n",
       "      <th>brand</th>\n",
       "      <th>traffic</th>\n",
       "      <th>impressions</th>\n",
       "      <th>payment</th>\n",
       "      <th>revenue</th>\n",
       "      <th>product_ad_spend</th>\n",
       "      <th>...</th>\n",
       "      <th>comment_received</th>\n",
       "      <th>product_rating</th>\n",
       "      <th>high_rating</th>\n",
       "      <th>high_discount</th>\n",
       "      <th>high_comment</th>\n",
       "      <th>avg_category_rate</th>\n",
       "      <th>avg_category_comment</th>\n",
       "      <th>week_of_month</th>\n",
       "      <th>wday</th>\n",
       "      <th>day_of_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3424</th>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>10070408774</td>\n",
       "      <td>Bình Ða D?ng 0.75L - Nh?p kh?u chính hãng 100%...</td>\n",
       "      <td>6. Other Melitta products</td>\n",
       "      <td>Melitta</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3425</th>\n",
       "      <td>2024-05-02</td>\n",
       "      <td>10070408774</td>\n",
       "      <td>Bình Ða D?ng 0.75L - Nh?p kh?u chính hãng 100%...</td>\n",
       "      <td>6. Other Melitta products</td>\n",
       "      <td>Melitta</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3426</th>\n",
       "      <td>2024-05-03</td>\n",
       "      <td>10070408774</td>\n",
       "      <td>Bình Ða D?ng 0.75L - Nh?p kh?u chính hãng 100%...</td>\n",
       "      <td>6. Other Melitta products</td>\n",
       "      <td>Melitta</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3427</th>\n",
       "      <td>2024-05-04</td>\n",
       "      <td>10070408774</td>\n",
       "      <td>Bình Ða D?ng 0.75L - Nh?p kh?u chính hãng 100%...</td>\n",
       "      <td>6. Other Melitta products</td>\n",
       "      <td>Melitta</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3428</th>\n",
       "      <td>2024-05-05</td>\n",
       "      <td>10070408774</td>\n",
       "      <td>Bình Ða D?ng 0.75L - Nh?p kh?u chính hãng 100%...</td>\n",
       "      <td>6. Other Melitta products</td>\n",
       "      <td>Melitta</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date   product_id  \\\n",
       "3424 2024-05-01  10070408774   \n",
       "3425 2024-05-02  10070408774   \n",
       "3426 2024-05-03  10070408774   \n",
       "3427 2024-05-04  10070408774   \n",
       "3428 2024-05-05  10070408774   \n",
       "\n",
       "                                           product_name  \\\n",
       "3424  Bình Ða D?ng 0.75L - Nh?p kh?u chính hãng 100%...   \n",
       "3425  Bình Ða D?ng 0.75L - Nh?p kh?u chính hãng 100%...   \n",
       "3426  Bình Ða D?ng 0.75L - Nh?p kh?u chính hãng 100%...   \n",
       "3427  Bình Ða D?ng 0.75L - Nh?p kh?u chính hãng 100%...   \n",
       "3428  Bình Ða D?ng 0.75L - Nh?p kh?u chính hãng 100%...   \n",
       "\n",
       "               product_category    brand  traffic  impressions  payment  \\\n",
       "3424  6. Other Melitta products  Melitta        0            0        0   \n",
       "3425  6. Other Melitta products  Melitta        0            0        0   \n",
       "3426  6. Other Melitta products  Melitta        0            0        0   \n",
       "3427  6. Other Melitta products  Melitta        0            0        0   \n",
       "3428  6. Other Melitta products  Melitta        0            0        0   \n",
       "\n",
       "      revenue  product_ad_spend  ...  comment_received  product_rating  \\\n",
       "3424        0                 0  ...                 0             0.0   \n",
       "3425        0                 0  ...                 0             0.0   \n",
       "3426        0                 0  ...                 0             0.0   \n",
       "3427        0                 0  ...                 0             0.0   \n",
       "3428        0                 0  ...                 0             0.0   \n",
       "\n",
       "      high_rating  high_discount  high_comment  avg_category_rate  \\\n",
       "3424            0              0             0                4.9   \n",
       "3425            0              0             0                4.9   \n",
       "3426            0              0             0                4.9   \n",
       "3427            0              0             0                4.9   \n",
       "3428            0              0             0                4.9   \n",
       "\n",
       "      avg_category_comment  week_of_month  wday  day_of_year  \n",
       "3424                     8              1     3          122  \n",
       "3425                     8              1     4          123  \n",
       "3426                     8              1     5          124  \n",
       "3427                     8              1     6          125  \n",
       "3428                     8              1     7          126  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the data by product_id and date\n",
    "demand = demand.sort_values(by=['product_id', 'date'])\n",
    "\n",
    "demand.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sine/cosine transforms time variables to capture periodicity and cyclic patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For cyclical encoding, use sine/cosine transforms\n",
    "def cyclical_encode(series, max_val):\n",
    "    # series are values from 1 to max_val\n",
    "    # Convert to 0-based: (value-1)\n",
    "    sine = np.sin(2 * np.pi * (series - 1) / max_val)\n",
    "    cosine = np.cos(2 * np.pi * (series - 1) / max_val)\n",
    "    return sine, cosine\n",
    "\n",
    "# Cyclical encode weekday (7 days in a week)\n",
    "demand['wday_sin'], demand['wday_cos'] = cyclical_encode(demand['wday'], 7)\n",
    "# Cyclical encode month (12 months)\n",
    "demand['month_sin'], demand['month_cos'] = cyclical_encode(demand['month'], 12)\n",
    "# Cyclical encode week_of_the_month (assume up to 5 weeks in a month)\n",
    "demand['wom_sin'], demand['wom_cos'] = cyclical_encode(demand['week_of_month'], 5)\n",
    "# Cyclical encode day_of_year (assume up to 365 days in a year)\n",
    "demand['day_of_year_sin'], demand['day_of_year_cos'] = cyclical_encode(demand['day_of_year'], 365)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lag and rolling features for important numeric columns\n",
    "How I defined 'important' is based on domain knowledge and intuition first, then we can refine features later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns to create the features on\n",
    "numeric_cols = ['payment', 'revenue', 'product_ad_spend', 'shop_ad_spend', 'auto_ad_spend']\n",
    "\n",
    "# Create lag features (e.g., lag_1, lag_3, lag_7, lag_14, lag_28)\n",
    "lag_periods = [3, 28]\n",
    "for col in numeric_cols:\n",
    "    if col in demand.columns:\n",
    "        for lag in lag_periods:\n",
    "            demand[f'{col}_lag_{lag}'] = demand.groupby('product_id')[col].shift(lag) #Reset lagging for every product_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create rolling features (example: 7-day rolling mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns to create the features on\n",
    "numeric_cols = ['traffic', 'impressions', 'payment', 'revenue', 'product_ad_spend', 'shop_ad_spend', 'auto_ad_spend']\n",
    "\n",
    "rolling_windows = [7, 28]  # Define the rolling windows\n",
    "for rolling_window in rolling_windows:\n",
    "    for col in numeric_cols:  # Ensure these are the numeric columns you want to apply rolling features to\n",
    "        if col in demand.columns:\n",
    "            demand[f'{col}_rolling_{rolling_window}d_mean'] = (\n",
    "                demand.groupby('product_id')[col] #Reset rolling for every product_id\n",
    "                .transform(lambda x: x.shift(1).rolling(rolling_window).mean())\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Category-level average within each month and each week\n",
    "* There are homogenous patterns for each `product_category` (reference 'M5 Competition'), so we need to extract category-level data for the model to enhance learning process.\n",
    "* Besides, in execution, it is easier to manage on category level, not on every single product level. So if we can learn anything helpful, we can apply into our category growth plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'product_category' in demand.columns:\n",
    "    # Daily aggregation\n",
    "    cat_rev = demand.groupby(['product_category', 'date'])['product_ad_spend'].mean().reset_index(name='cat_daily_avg_product_ad_spend')\n",
    "    cat_traffic = demand.groupby(['product_category', 'date'])['traffic'].mean().reset_index(name='cat_daily_avg_traffic')\n",
    "\n",
    "    # Monthly aggregation\n",
    "    cat_month_rev = demand.groupby(['product_category', 'month'])['product_ad_spend'].mean().reset_index(name='cat_month_avg_product_ad_spend')\n",
    "    cat_month_traffic = demand.groupby(['product_category', 'month'])['traffic'].mean().reset_index(name='cat_month_avg_traffic')\n",
    "\n",
    "    # Weekly aggregation (assuming 'week_of_month' corresponds to the day of the week)\n",
    "    cat_week_rev = demand.groupby(['product_category', 'week_of_month'])['product_ad_spend'].mean().reset_index(name='cat_week_avg_product_ad_spend')\n",
    "    cat_week_traffic = demand.groupby(['product_category', 'week_of_month'])['traffic'].mean().reset_index(name='cat_week_avg_traffic')\n",
    "\n",
    "    # Merging daily aggregated values back to the main dataframe\n",
    "    demand = pd.merge(demand, cat_rev, on=['product_category', 'date'], how='left')\n",
    "    demand = pd.merge(demand, cat_traffic, on=['product_category', 'date'], how='left')\n",
    "\n",
    "    # Merging monthly aggregated values\n",
    "    demand = pd.merge(demand, cat_month_rev, on=['product_category', 'month'], how='left')\n",
    "    demand = pd.merge(demand, cat_month_traffic, on=['product_category', 'month'], how='left')\n",
    "\n",
    "    # Merging weekly aggregated values\n",
    "    demand = pd.merge(demand, cat_week_rev, on=['product_category', 'week_of_month'], how='left')\n",
    "    demand = pd.merge(demand, cat_week_traffic, on=['product_category', 'week_of_month'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Continuous zero-sale days until today\n",
    "I learned about `continuous_zero_sales_days` from the repetitive feature engineering practices in the M5 competition. I believe this feature is highly effective in helping the model understand sporadic sales patterns for certain `product_id`s and `product_category`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4840/269506180.py:11: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  demand.groupby('product_id', group_keys=False).apply(continuous_zero_sales)\n"
     ]
    }
   ],
   "source": [
    "# Sort data to ensure it is in time order\n",
    "demand = demand.sort_values(by=['product_id', 'date'])\n",
    "\n",
    "# Define continuous zero-sale days\n",
    "def continuous_zero_sales(group):\n",
    "    zero_sales_days = (group['payment'] == 0).astype(int)  # 1 if no sale, 0 otherwise\n",
    "    return zero_sales_days.groupby((zero_sales_days != zero_sales_days.shift()).cumsum()).cumsum()\n",
    "\n",
    "# Apply the function for each product_id\n",
    "demand['continuous_zero_sales_days'] = (\n",
    "    demand.groupby('product_id', group_keys=False).apply(continuous_zero_sales)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this feature is important, to create lagging and rolling features for it is not a bad idea, I reckon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling features for `continuous_zero_sales_days` on product_id level\n",
    "# Rolling window of 14 days is based on domain knowledge and reviewing the dataset\n",
    "rolling_window = 14\n",
    "demand['zero_sales_rolling_mean_14d'] = (\n",
    "    demand.groupby('product_id')['continuous_zero_sales_days']\n",
    "          .transform(lambda x: x.rolling(rolling_window, min_periods=1).mean())\n",
    ")\n",
    "demand['zero_sales_rolling_max_14d'] = (\n",
    "    demand.groupby('product_id')['continuous_zero_sales_days']\n",
    "          .transform(lambda x: x.rolling(rolling_window, min_periods=1).max())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category level zero_sales_rolling_mean_14d\n",
    "# Compute category-level average of zero_sales_rolling_mean_14d\n",
    "cat_rolling_avg_zero_sales_14d = (\n",
    "    demand.groupby(['product_category', 'date'])['zero_sales_rolling_mean_14d']\n",
    "          .mean()\n",
    "          .reset_index()\n",
    "          .rename(columns={'zero_sales_rolling_mean_14d': 'cat_rolling_avg_zero_sales_14d'})\n",
    ")\n",
    "\n",
    "# Merge back to the original DataFrame\n",
    "demand = pd.merge(demand, cat_rolling_avg_zero_sales_14d, on=['product_category', 'date'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interaction between category-level rolling zero sales and promotion\n",
    "demand['cat_zero_sales_x_promotion'] = (\n",
    "    demand['cat_rolling_avg_zero_sales_14d'] * demand['promotion_on']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0: Ensure data is sorted by 'product_category' and 'date'\n",
    "demand = demand.sort_values(by=['product_category', 'date'])\n",
    "\n",
    "# Trend in rolling average of `continuous_zero_sales_days`\n",
    "# Step 1: Compute category-level trend of zero_sales_rolling_mean_14d\n",
    "# Ensure it considers time order properly\n",
    "cat_trend = (\n",
    "    demand.groupby(['product_category', 'date'])['cat_rolling_avg_zero_sales_14d']\n",
    "          .mean()  # Aggregate for consistent value per 'product_category' and 'date'\n",
    "          .groupby(level=0)  # Group again by 'product_category'\n",
    "          .transform(lambda x: x.diff(14))  # Calculate 14-day trend\n",
    "          .reset_index(name='cat_rolling_avg_zero_sales_trend_14d')  # Create a new DataFrame\n",
    ")\n",
    "\n",
    "# Step 2: Merge back to the original DataFrame on 'product_category' and 'date'\n",
    "demand = pd.merge(demand, cat_trend, on=['product_category', 'date'], how='left')\n",
    "\n",
    "# Percentage changes in rolling average of `continuous_zero_sales_days`\n",
    "# Step 1: Compute category-level trend of zero_sales_rolling_mean_14d\n",
    "# Ensure it considers time order properly\n",
    "cat_pect_trend = (\n",
    "    demand.groupby(['product_category', 'date'])['cat_rolling_avg_zero_sales_14d']\n",
    "          .mean()  # Aggregate for consistent value per 'product_category' and 'date'\n",
    "          .groupby(level=0)  # Group again by 'product_category'\n",
    "          .transform(lambda x: x.pct_change(14))  # Calculate 14-day trend\n",
    "          .reset_index(name='cat_rolling_avg_zero_sales_pct_change_14d')  # Create a new DataFrame\n",
    ")\n",
    "\n",
    "# Step 2: Merge back to the original DataFrame on 'product_category' and 'date'\n",
    "demand = pd.merge(demand, cat_pect_trend, on=['product_category', 'date'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort data to ensure it is in time order\n",
    "demand = demand.sort_values(by=['date', 'product_id'])\n",
    "\n",
    "# Lagged values of category-level zero sales rolling average\n",
    "for lag in [7, 14, 28]:\n",
    "    demand[f'cat_rolling_avg_zero_sales_lag_{lag}d'] = (\n",
    "        demand.groupby('product_id')['cat_rolling_avg_zero_sales_14d']\n",
    "              .transform(lambda x: x.shift(lag))\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized price-related variables:\n",
    "* Scale: category level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Group by 'product_category' and calculate mean and std for 'avg_price' and 'promotion_price'\n",
    "category_stats = demand.groupby('product_category').agg(\n",
    "    avg_price_mean=('avg_price', 'mean'),\n",
    "    avg_price_std=('avg_price', 'std'),\n",
    "    promotion_price_mean=('promotion_price', 'mean'),\n",
    "    promotion_price_std=('promotion_price', 'std')\n",
    ").reset_index()\n",
    "\n",
    "# Step 2: Merge these statistics back to the original DataFrame\n",
    "demand = pd.merge(demand, category_stats, on='product_category', how='left')\n",
    "\n",
    "# Step 3: Create normalized columns\n",
    "demand['normalized_avg_price'] = (demand['avg_price'] - demand['avg_price_mean']) / demand['avg_price_std']\n",
    "demand['normalized_promotion_price'] = (demand['promotion_price'] - demand['promotion_price_mean']) / demand['promotion_price_std']\n",
    "\n",
    "# Dropping unnecessary intermediate columns for cleanliness (optional)\n",
    "demand = demand.drop(columns=['avg_price_mean', 'avg_price_std', 'promotion_price_mean', 'promotion_price_std'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features based on domain knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ad spend during promotion, weekend\n",
    "if 'promotion_on' in demand.columns and 'product_ad_spend' in demand.columns:\n",
    "    demand['ad_spend_during_promotion'] = demand['product_ad_spend'] * demand['promotion_on']\n",
    "\n",
    "if 'weekend' in demand.columns and 'product_ad_spend' in demand.columns:\n",
    "    demand['weekend_ad_spend'] = demand['weekend'] * demand['product_ad_spend']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CTR\n",
    "if 'traffic' in demand.columns and 'impressions' in demand.columns:\n",
    "    demand['CTR'] = np.where(demand['impressions'] == 0, 0, demand['traffic'] / demand['impressions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last steps\n",
    "## One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical features for one-hot encoding\n",
    "cat_cols = []\n",
    "for col in ['product_category', 'brand', 'price_bin']:\n",
    "    if col in demand.columns and demand[col].dtype == 'object':\n",
    "        cat_cols.append(col)\n",
    "\n",
    "# Perform one-hot encoding\n",
    "if cat_cols:\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)  # Use sparse_output instead of sparse\n",
    "    # Fit-transform\n",
    "    ohe_data = ohe.fit_transform(demand[cat_cols])\n",
    "    # Create a DataFrame with OHE results\n",
    "    ohe_df = pd.DataFrame(ohe_data, columns=ohe.get_feature_names_out(cat_cols), index=demand.index)\n",
    "    # Concatenate back\n",
    "    demand = pd.concat([demand.drop(cat_cols, axis=1), ohe_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the high cardinality of `product_id`, one-hot encoding is not a suitable approach.\n",
    "\n",
    "So I'll try target encoding on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target encoding: product_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate a target encoder\n",
    "te = ce.TargetEncoder(cols=['product_id'])\n",
    "\n",
    "# Fit the encoder on the training set\n",
    "demand['product_id_target_enc'] = te.fit_transform(demand['product_id'], demand['payment'])\n",
    "\n",
    "# Drop original if desired\n",
    "demand.drop('product_id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop columns to avoid duplication in learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand = demand.drop(['wday', 'month', 'week_of_month', 'product_name', 'day_of_year'], axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
